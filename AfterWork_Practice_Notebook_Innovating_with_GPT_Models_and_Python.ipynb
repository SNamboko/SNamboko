{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SNamboko/SNamboko/blob/main/AfterWork_Practice_Notebook_Innovating_with_GPT_Models_and_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AfterWork Practice Notebook: Innovating with GPT Models and Python"
      ],
      "metadata": {
        "id": "gEG9v4Nl8Mqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Installing the required libraries"
      ],
      "metadata": {
        "id": "OQ2ZtZE78bC0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22pcSMrspy-f"
      },
      "outputs": [],
      "source": [
        "# install libraries\n",
        "!pip3 install openai transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the !pip3 install command to install the openai and transformers packages to our local environment. These packages contain modules and functions that allow us to interact with OpenAI's API and perform natural language processing tasks, respectively."
      ],
      "metadata": {
        "id": "brqzK5Ke8Hh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries after installation\n",
        "import openai\n",
        "import transformers\n",
        "\n",
        "# set OpenAI API key\n",
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "Izu8bQeD5a5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the packages are installed, we can import them into our code using the import statement. We then set up our OpenAI API credentials using our API key."
      ],
      "metadata": {
        "id": "8oDib4uc8IUo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0H1iI-Rly01"
      },
      "source": [
        "# 2. GPT-3: text-davinci-003 for Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DX0H3gRsmGgl"
      },
      "outputs": [],
      "source": [
        "# Example text to be classified\n",
        "text = \"I love this workshop, it's so much fun!\"\n",
        "\n",
        "# Define the classification prompt\n",
        "prompt = (f\"Please classify the following text as either positive, negative, or neutral:\\n\"\n",
        "          f\"Text: {text}\\n\"\n",
        "          f\"Sentiment: \")\n",
        "\n",
        "# Function to generate classification using text-davinci-003\n",
        "def classify_text(text):\n",
        "    completions = openai.Completion.create(\n",
        "        engine = \"text-davinci-003\", prompt = prompt, max_tokens = 1024, n = 1, stop = None\n",
        "    )\n",
        "    return completions.choices[0].text.strip()\n",
        "\n",
        "# Generate classification using text-davinci-003\n",
        "classification = classify_text(text)\n",
        "\n",
        "# Print the generated classification\n",
        "print(\"Classification:\", classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a piece of text as a string variable named \"text\". We then create a string variable named \"prompt\" which is a message that asks the user to classify the \"text\" variable as positive, negative or neutral.\n",
        "\n",
        "We then define a function \"classify_text\" that uses the OpenAI API \"text-davinci-003\" to generate a classification for the \"text\" variable. This function takes in the \"text\" variable as an argument and sends it to the OpenAI API. The API generates a response based on the \"prompt\" string defined earlier and returns a classification as a string. The classification is stored in the \"classification\" variable.\n",
        "\n",
        "Finally, we print out the generated classification using the \"print()\" function. The output will display the word \"Classification:\" followed by the classification generated by the API."
      ],
      "metadata": {
        "id": "x9Kfc2M91--H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge"
      ],
      "metadata": {
        "id": "PHh7KejJ3Mv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are tasked with creating a sentiment analysis tool using Python and the OpenAI API to classify the sentiment of tweets.\n",
        "\n",
        "Your program should take a user input of a tweet and classify it as either positive, negative, or neutral using the OpenAI API. The program should output the classification and the original tweet.\n",
        "\n",
        "You can use the following code as a starting point:"
      ],
      "metadata": {
        "id": "wCAPpahY3OD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here's your code:\n",
        "\n",
        "# Define the classification prompt\n",
        "def get_sentiment(tweet):\n",
        "    prompt = (f\"Please classify the following tweet as either positive, negative, or neutral:\\n\"\n",
        "              f\"Tweet: {tweet}\\n\"\n",
        "              f\"Sentiment: \")\n",
        "    \n",
        "    # Generate classification using text-davinci-003\n",
        "    completions = openai.Completion.create(\n",
        "        # your code goes here\n",
        "    )\n",
        "    \n",
        "    # Return the classification\n",
        "    return completions.choices[0].text.strip()\n",
        "\n",
        "# Get user input\n",
        "tweet = input(\"Enter a tweet: \")\n",
        "\n",
        "# Get sentiment of tweet\n",
        "classification = get_sentiment(tweet)\n",
        "\n",
        "# Print results\n",
        "print(\"Tweet:\", tweet)\n",
        "print(\"Classification:\", classification)"
      ],
      "metadata": {
        "id": "jVizAzdw3SiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtAQurVtlqtY"
      },
      "source": [
        "# 3. GPT-3: gpt-3.5-turbo for Question Answering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set your question\n",
        "input_text = \"How many countries does Africa have?\"\n",
        "\n",
        "# send an API request to obtain the necessary information\n",
        "response = openai.ChatCompletion.create(\n",
        "   model = \"gpt-3.5-turbo\",\n",
        "   messages=[{\"role\": \"user\", \"content\": input_text }]\n",
        ")\n",
        "\n",
        "# Parse the response and output the result\n",
        "output_text = response['choices'][0]['message']['content']\n",
        "\n",
        "# print your question and the answer\n",
        "print(\"Your question:\", input_text)\n",
        "print(\"ChatGPT API reply:\", output_text)"
      ],
      "metadata": {
        "id": "Eas1hCwnmCD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by setting the variable input_text to the string \"How many countries does Africa have?\". This variable will serve as the input to the ChatGPT API request.\n",
        "\n",
        "Then, we send a request to the OpenAI API using openai.ChatCompletion.create(). This method takes several arguments, including the model to use and the messages to send. Here, we specify the model as \"gpt-3.5-turbo\", which is a pre-trained language model by OpenAI. We also specify the messages to send as a list with a single dictionary, where the role is \"user\" and the content is our input question, input_text.\n",
        "\n",
        "After we receive a response from the API, we extract the output text using response['choices'][0]['message']['content']. This returns the message generated by the API in response to our input question.\n",
        "\n",
        "Finally, we print the input question and the generated response using print(). The output will be displayed in the console as \"Your question: How many countries does Africa have?\" and \"ChatGPT API reply: Africa is made up of 54 recognized states, plus some other territories.\", respectively."
      ],
      "metadata": {
        "id": "uEHcPA_C4Rln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge"
      ],
      "metadata": {
        "id": "cZSSWUXE32hu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You are tasked with creating a trivia quiz game using Python and the OpenAI API to generate questions and answers.\n",
        "\n",
        "Your program should generate a random trivia question using the OpenAI API and prompt the user to enter their answer. The program should then compare the user's answer to the correct answer generated by the API and provide feedback."
      ],
      "metadata": {
        "id": "flH_UU5Z35SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Generate a random trivia question\n",
        "def get_question():\n",
        "    topics = [\"history\", \"science\", \"geography\", \"entertainment\", \"sports\"]\n",
        "    prompt = f\"Please generate a trivia question about {random.choice(topics)}.\\n\"\n",
        "    \n",
        "    # Generate question using curie engine\n",
        "    completions = openai.Completion.create(\n",
        "        engine=\"\", prompt=prompt, max_tokens=1024, n=1, stop=None\n",
        "    )\n",
        "    \n",
        "    # Extract the question from the API response\n",
        "    question = completions.choices[0].text.strip()\n",
        "    \n",
        "    return question\n",
        "\n",
        "# Check if the user's answer is correct\n",
        "def check_answer(question, user_answer):\n",
        "    # Send question and user answer to ChatGPT API\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"\",\n",
        "        prompt=f\"Q: {question}\\nA: {user_answer}\\n\",\n",
        "        temperature=0.0,\n",
        "        max_tokens=1\n",
        "    )\n",
        "    \n",
        "    # Parse the response and extract the answer\n",
        "    answer = response.choices[0].text.strip()\n",
        "    \n",
        "    # Check if the answer is correct\n",
        "    if \"correct\" in answer.lower():\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "# Generate a random question\n",
        "question = get_question()\n",
        "\n",
        "# Prompt user for an answer\n",
        "user_answer = input(f\"Q: {question}\\nA: \")\n",
        "\n",
        "# Check if the answer is correct\n",
        "is_correct = check_answer(question, user_answer)\n",
        "\n",
        "# Print the result\n",
        "if is_correct:\n",
        "    print(\"Correct!\")\n",
        "else:\n",
        "    print(\"Incorrect.\") "
      ],
      "metadata": {
        "id": "1uVspPBf3582"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. DALL-E for Image Generation"
      ],
      "metadata": {
        "id": "CtTZiLYXvDjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set prompt to use\n",
        "prompt = \"a ship sailing against the night sky\"\n",
        "\n",
        "# send an API request to generate your image\n",
        "response = openai.Image.create(\n",
        "  prompt = prompt, n = 1, size = \"512x512\"\n",
        ")\n",
        "\n",
        "# obtain the image URL\n",
        "image_url = response['data'][0]['url']\n",
        "\n",
        "# print the image URL\n",
        "print(\"Image URL:\", image_url)"
      ],
      "metadata": {
        "id": "9okMlI2kMh1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using OpenAI's Image API to generate an image based on the prompt \"a ship sailing against the night sky\". We send a request to the API with the prompt and some additional parameters such as the number of images to generate and the size of the image. We then extract the URL of the generated image from the API response and print it out.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fhbRz3x57zYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Whisper for Audio Translation"
      ],
      "metadata": {
        "id": "-bU0eF7pvFxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Audio File Download link: https://drive.google.com/file/d/1CFcZ70f2CMpV4kEFVfJU4wBYnwmEG7IV/view?usp=share_link"
      ],
      "metadata": {
        "id": "jsb5fClP7n7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the path to the audio file you want to transcribe\n",
        "audio_file= open(\"generated_audio.wav\", \"rb\")\n",
        "\n",
        "# send an API request to transcribe the audio file\n",
        "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
        "\n",
        "# print the transcribed text\n",
        "print(\"Transcribed text:\\n\")\n",
        "print(transcript)"
      ],
      "metadata": {
        "id": "t9RR6nO21z1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we are transcribing an audio file using the OpenAI API. First, we set the path to the audio file that we want to transcribe. Then, we send an API request to transcribe the audio file using the openai.Audio.transcribe() function. We pass the audio file path and the whisper-1 model as parameters to this function. Finally, we print the transcribed text using the print() function.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sm-aDsYw7bNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Text Generation and Question Answering with GPT-2\n",
        "**Note:** Running this code might take quite a while. "
      ],
      "metadata": {
        "id": "YtU4neNrK7JP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the modules for text generation and tokenization\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer \n",
        "\n",
        "# load the model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium') \n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2-medium', pad_token_id = tokenizer.eos_token_id)\n",
        "\n",
        "# set your prompt\n",
        "prompt = 'What is a language model?'\n",
        "\n",
        "# define the input\n",
        "input_ids = tokenizer.encode(prompt, return_tensors = 'pt') \n",
        "\n",
        "# define the output\n",
        "output = model.generate(input_ids, max_length = 500, num_beams = 5, no_repeat_ngram_size = 2, early_stopping = True) \n",
        "\n",
        "# display the result\n",
        "print (tokenizer.decode(output[0], skip_special_tokens=True )) "
      ],
      "metadata": {
        "id": "LznZCtR_fNP1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "gEG9v4Nl8Mqq",
        "OQ2ZtZE78bC0",
        "W0H1iI-Rly01",
        "PHh7KejJ3Mv2",
        "NtAQurVtlqtY",
        "cZSSWUXE32hu",
        "CtTZiLYXvDjJ",
        "-bU0eF7pvFxn",
        "YtU4neNrK7JP"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}